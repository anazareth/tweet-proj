{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "trudeau = pd.read_csv('data//trudeau_clean.csv', encoding='utf-8')\n",
    "trump = pd.read_csv('data//trump_clean.csv', encoding='utf-8')\n",
    "user_dfs = {'trudeau':trudeau, 'trump':trump}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all links\n",
    "user_dfs['trump']['Tweets'] = user_dfs['trump']['Tweets'].str.replace('https:\\/\\/t\\.co\\/[-a-zA-Z0-9]{1,256}', '')\n",
    "# trim off whitespace from front and back of tweets\n",
    "user_dfs['trump']['Tweets'] = user_dfs['trump']['Tweets'].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDC Director was totally misquoted by Fake News @CNN on Covid 19. He will be putting out a statement.\n",
      "-----\n",
      "“Economic impact of Covid-19.” @foxandfriends Very interesting analysis. Light at the end of the tunnel. Thank you!\n",
      "-----\n",
      "....to State/Local Governments for lost revenues from COVID 19 much needed Infrastructure Investments for Bridges Tunnels Broadband Tax Incentives for Restaurants Entertainment Sports and Payroll Tax Cuts to increase Economic Growth.\n",
      "-----\n",
      "“On February 19th there was a Democratic Debate in Las Vegas. Three words weren’t said: Virus CoronaVirus or COVID19. NEVER came up!” @BretBaier\n",
      "-----\n",
      "Having been involved in the negotiations to put it mildly the number that OPEC+ is looking to cut is 20 Million Barrels a day not the 10 Million that is generally being reported. If anything near this happens and the World gets back to business from the Covid 19.....\n",
      "-----\n",
      "America owes our very hard working food supply workers so much as they produce and deliver high quality food for us during this horrible COVID-19. Join me in thanking our Farmers Ranchers Processors Distributors and Stores! @JohnBoozman\n",
      "-----\n",
      "30 DAYS TO SLOW THE SPREAD#COVIDー19\n",
      "-----\n",
      "A great early result from a drug that will start tomorrow in New York and other places! #COVIDー19\n",
      "-----\n",
      "America’s Private Sector is stepping up to help us be STRONG! Many of the Nation’s distillers large and small are producing and donating hand sanitizer to help fight #COVID19. THANK YOU!\n",
      "-----\n",
      "Just had a nice conversation with Prime Minister @JustinTrudeau of Canada. Great to hear that his wonderful wife Sophie is doing very well. The United States and Canada will continue to coordinate closely together on COVID-19.\n",
      "-----\n",
      "COVID-19 UPDATE\n",
      "-----\n",
      "Just finished a meeting on Covid-19 in the Situation Room news conference coming up shortly.\n",
      "-----\n",
      "Attending meetings on Covid-19 in the White House. Working with States and local governments many of whom have done a great job. Full report latter!\n",
      "-----\n",
      "Texas Supreme Court: Lack of immunity to COVID-19 alone not enough to vote by mail   Big win in Texas on the dangerous Mail In Voting Scam!\n",
      "-----\n",
      "The Radical Left Lamestream Media together with their partner the Do Nothing Democrats are trying to spread a new narrative that President Trump was slow in reacting to Covid 19. Wrong I was very fast even doing the Ban on China long before anybody thought necessary!\n",
      "-----\n",
      "Great reviews on our handling of Covid 19 sometimes referred to as the China Virus. Ventilators Testing Medical Supply Distribution we made a lot of Governors look very good - And got no credit for so doing. Most importantly we helped a lot of great people!\n",
      "-----\n",
      "I give and have given from the beginning my entire yearly salary $400000 to $450000 back to our government. Last check to HHS Covid relief. My great honor!\n",
      "-----\n",
      "The United States cannot have all Mail In Ballots. It will be the greatest Rigged Election in history. People grab them from mailboxes print thousands of forgeries and “force” people to sign. Also forge names. Some absentee OK when necessary. Trying to use Covid for this Scam!\n",
      "-----\n",
      "We’ve done a GREAT job on Covid response making all Governors look good some fantastic (and that’s OK) but the Lamestream Media doesn’t want to go with that narrative and the Do Nothing Dems talking point is to say only bad about “Trump”. I made everybody look good but me!\n",
      "-----\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "# exploratory - regex for finding key words/phrases\n",
    "import re\n",
    "\n",
    "target_phrase = 'covid'\n",
    "\n",
    "matching_tweets=[]\n",
    "for t in trump['Tweets']:\n",
    "    if re.search(target_phrase, t.lower()) is not None:\n",
    "        matching_tweets.append(t)\n",
    "        print(t)\n",
    "        print('-----')\n",
    "print(len(matching_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# punctuation to strip from tweets (note omission of underscore)\n",
    "punctuation = '!\"$%&\\'\\’“()*+,-./:;<=>?[\\\\]^`{|}~'\n",
    "# characters that appear as words after splitting (to remove)\n",
    "bad_chars = [',','.',';','!',':','’','-','&','“','”','...','(',')','?','%',\n",
    "             '', '&amp;','به','را','و','ایران','और','–']\n",
    "\n",
    "english_stopwords = set(stopwords.words('english'))  # common uninteresting words\n",
    "# empirically added words to remove\n",
    "more_stopwords = {'dont','get','make','even','also','time','said','far','amp','new','would','like','us',\n",
    "                  'back','two','its','many','want','done','made','really','yet','got','nothing',\n",
    "                 'ever','read','one','last','well','way','total','see','look','complete','didnt',\n",
    "                 'keep','today','go','going','must','years','much','pm','always','first','day','let',\n",
    "                  'know','open','others','better','small','say','need','come','long','doesnt',\n",
    "                  'wrong','happen','true','everything','getting','three','zero','fact','knew',\n",
    "                 'ago','including','already','right','every','things','never','fast'}\n",
    "# 'good','bad',''\n",
    "words_to_remove = more_stopwords.union(english_stopwords)  # all words to remove\n",
    "# want to count the following common Trump phrases as one word:\n",
    "trumpisms = {'fake news':'fake_news', 'do nothing democrats':'do_nothing_democrats',\n",
    "            'do nothing dems':'do_nothing_democrats','impeachment hoax':'impeachment_hoax',\n",
    "            'white house':'white_house','thank you':'thank_you', 'second amendment':'second_amendment',\n",
    "             'new york':'new_york', 'witch hunt':'witch_hunt',\n",
    "            'mini mike':'mini_mike','cryin chuck':'cryin_chuck'}\n",
    "            # 'sleepy joe':'sleepy_joe', 'crazy bernie':'crazy_bernie'\n",
    "    \n",
    "        \n",
    "def tokenize_tweet(tweet):\n",
    "    tweet = tweet.lower()  # only want lowercase letters\n",
    "    tweet = tweet.translate(str.maketrans('','',punctuation))\n",
    "    for orig, new in trumpisms.items():\n",
    "        tweet = tweet.replace(orig, new)\n",
    "\n",
    "    words = tweet.split(sep=' ')\n",
    "    keywords = []\n",
    "    for w in words:\n",
    "        if w==\"it's\":\n",
    "            print(tweet)\n",
    "        if w not in words_to_remove and w not in bad_chars:\n",
    "            keywords.append(w)\n",
    "    return keywords\n",
    "\n",
    "users = ['trump']\n",
    "kw_dict = {u: None for u in users}\n",
    "for u in users:\n",
    "    keyword_freq = pd.DataFrame()\n",
    "    for m in ['January','February','March','April','May']:  # get top words from each month, create df\n",
    "        mth = m.lower()[0:3]  # first three letters of lowercase month\n",
    "        mth_tweets = user_dfs[u].loc[user_dfs[u]['Month']==m]['Tweets']  # tweets from specific month\n",
    "        words = pd.Series(np.concatenate([tokenize_tweet(t) for t in mth_tweets])).value_counts()[0:100]\n",
    "        keyword_freq['kw_'+mth] = words.index\n",
    "        keyword_freq['freq_'+mth] = words.values\n",
    "    words = pd.Series(np.concatenate([tokenize_tweet(t) for t in user_dfs[u]['Tweets']])).value_counts()[0:100]\n",
    "    keyword_freq['kw_all'] = words.index\n",
    "    keyword_freq['freq_all'] = words.values\n",
    "#     print(keyword_freq)\n",
    "    kw_dict[u] = keyword_freq\n",
    "    keyword_freq.to_csv('data//kw_ana//'+u+'_words.csv', header=True, encoding='utf-8',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Date</th>\n",
       "      <th>RTs</th>\n",
       "      <th>Favourites</th>\n",
       "      <th>isRT</th>\n",
       "      <th>id_str</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1598</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Let New York’s Finest be New York’s Finest. Th...</td>\n",
       "      <td>2020-05-31 02:12:14</td>\n",
       "      <td>33863</td>\n",
       "      <td>202862</td>\n",
       "      <td>False</td>\n",
       "      <td>1266915358914621440</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>The National Guard has been released in Minnea...</td>\n",
       "      <td>2020-05-31 02:08:42</td>\n",
       "      <td>62393</td>\n",
       "      <td>293293</td>\n",
       "      <td>False</td>\n",
       "      <td>1266914470066036736</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td></td>\n",
       "      <td>2020-05-31 00:54:36</td>\n",
       "      <td>27811</td>\n",
       "      <td>87057</td>\n",
       "      <td>False</td>\n",
       "      <td>1266895821083234304</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1601</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>MN Gov. Walz: We Estimate 80% of the Rioters A...</td>\n",
       "      <td>2020-05-31 00:20:50</td>\n",
       "      <td>20742</td>\n",
       "      <td>59221</td>\n",
       "      <td>False</td>\n",
       "      <td>1266887324505382912</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1602</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Hopefully a great successful and safe ROCKET L...</td>\n",
       "      <td>2020-05-30 18:37:07</td>\n",
       "      <td>19300</td>\n",
       "      <td>143675</td>\n",
       "      <td>False</td>\n",
       "      <td>1266800827621990400</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2143</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>The Governor of Michigan should give a little ...</td>\n",
       "      <td>2020-05-01 12:42:23</td>\n",
       "      <td>40674</td>\n",
       "      <td>210242</td>\n",
       "      <td>False</td>\n",
       "      <td>1256202305680158720</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2144</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Cryin Chuck Schumer compared to what other Sen...</td>\n",
       "      <td>2020-05-01 12:14:36</td>\n",
       "      <td>21049</td>\n",
       "      <td>90556</td>\n",
       "      <td>False</td>\n",
       "      <td>1256195312965877760</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2145</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Cryin’ Chuck Schumer was on a late night show ...</td>\n",
       "      <td>2020-05-01 12:07:51</td>\n",
       "      <td>25324</td>\n",
       "      <td>110033</td>\n",
       "      <td>False</td>\n",
       "      <td>1256193615724007425</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2146</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Dirty Cop!</td>\n",
       "      <td>2020-05-01 11:55:42</td>\n",
       "      <td>19665</td>\n",
       "      <td>82710</td>\n",
       "      <td>False</td>\n",
       "      <td>1256190556839051264</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2147</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>I have done more for farmers and ranchers than...</td>\n",
       "      <td>2020-05-01 11:54:13</td>\n",
       "      <td>15460</td>\n",
       "      <td>68866</td>\n",
       "      <td>False</td>\n",
       "      <td>1256190183298473985</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>550 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Source                                             Tweets  \\\n",
       "1598  Twitter for iPhone  Let New York’s Finest be New York’s Finest. Th...   \n",
       "1599  Twitter for iPhone  The National Guard has been released in Minnea...   \n",
       "1600  Twitter for iPhone                                                      \n",
       "1601  Twitter for iPhone  MN Gov. Walz: We Estimate 80% of the Rioters A...   \n",
       "1602  Twitter for iPhone  Hopefully a great successful and safe ROCKET L...   \n",
       "...                  ...                                                ...   \n",
       "2143  Twitter for iPhone  The Governor of Michigan should give a little ...   \n",
       "2144  Twitter for iPhone  Cryin Chuck Schumer compared to what other Sen...   \n",
       "2145  Twitter for iPhone  Cryin’ Chuck Schumer was on a late night show ...   \n",
       "2146  Twitter for iPhone                                         Dirty Cop!   \n",
       "2147  Twitter for iPhone  I have done more for farmers and ranchers than...   \n",
       "\n",
       "                     Date    RTs  Favourites   isRT               id_str Month  \n",
       "1598  2020-05-31 02:12:14  33863      202862  False  1266915358914621440   May  \n",
       "1599  2020-05-31 02:08:42  62393      293293  False  1266914470066036736   May  \n",
       "1600  2020-05-31 00:54:36  27811       87057  False  1266895821083234304   May  \n",
       "1601  2020-05-31 00:20:50  20742       59221  False  1266887324505382912   May  \n",
       "1602  2020-05-30 18:37:07  19300      143675  False  1266800827621990400   May  \n",
       "...                   ...    ...         ...    ...                  ...   ...  \n",
       "2143  2020-05-01 12:42:23  40674      210242  False  1256202305680158720   May  \n",
       "2144  2020-05-01 12:14:36  21049       90556  False  1256195312965877760   May  \n",
       "2145  2020-05-01 12:07:51  25324      110033  False  1256193615724007425   May  \n",
       "2146  2020-05-01 11:55:42  19665       82710  False  1256190556839051264   May  \n",
       "2147  2020-05-01 11:54:13  15460       68866  False  1256190183298473985   May  \n",
       "\n",
       "[550 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_dfs[u].loc[user_dfs[u]['Month']==m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: loop over months and user?\n",
    "\n",
    "mth='may'\n",
    "u='trump'\n",
    "\n",
    "top100_words = list(kw_dict[u]['kw_'+mth])\n",
    "top100_set = set(top100_words)\n",
    "adj_mat = pd.DataFrame(0, index=top100_words, columns=top100_words)  # weighted adjacency matrix (init with 0's)\n",
    "mth_tweets = user_dfs[u].loc[user_dfs[u]['Month']==m]['Tweets']\n",
    "\n",
    "for twt in mth_tweets:  # for each tweet\n",
    "    tweet_words = set(tokenize_tweet(twt)) & top100_set  # set intersection (don't care about words outside top 100)\n",
    "    for wrd in tweet_words:  # for each word in the tweet\n",
    "        wrd_pos = top100_words.index(wrd)\n",
    "        remaining_words = set(tweet_words) - {wrd}\n",
    "        for rem in remaining_words:  # for each other word in the tweet\n",
    "            rem_pos = top100_words.index(rem)\n",
    "            if rem_pos<wrd_pos:  # want consistent ordering so that adj matrix is upper trian\n",
    "                adj_mat.loc[rem,wrd] = adj_mat.loc[rem,wrd] + 1\n",
    "            else:\n",
    "                adj_mat.loc[wrd,rem] = adj_mat.loc[wrd,rem] + 1\n",
    "adj_mat.to_csv('data///kw_ana//'+u+'_adjmat_may.csv',sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
